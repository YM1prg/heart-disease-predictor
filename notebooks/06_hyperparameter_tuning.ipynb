{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Rj7PtqMgzX"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE1Aw4JVMXv-",
        "outputId": "23d7b7f2-d3e5-44dd-da31-5436b2ca0833"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.8.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b9DkiakvmMN"
      },
      "source": [
        "#### the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "gi7vJl0fvkB1"
      },
      "outputs": [],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_iAs6b2pwZ1",
        "outputId": "54c506a0-f4ad-43bf-b26c-729815e17b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Baseline Model Performance:\n",
            "                 Model  Accuracy  Precision  Recall     F1    AUC\n",
            "0  Logistic Regression     0.885      0.862   0.893  0.877  0.953\n",
            "1        Decision Tree     0.770      0.719   0.821  0.767  0.774\n",
            "2        Random Forest     0.869      0.833   0.893  0.862  0.938\n",
            "3                  SVM     0.902      0.923   0.857  0.889  0.955\n"
          ]
        }
      ],
      "source": [
        "# Baseline results (from your current models)\n",
        "baseline_results = []\n",
        "\n",
        "for name, model in trained_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    baseline_results.append([name, acc, prec, rec, f1, auc])\n",
        "\n",
        "# Convert to DataFrame\n",
        "baseline_df = pd.DataFrame(baseline_results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"])\n",
        "print(\"ðŸ“Š Baseline Model Performance:\")\n",
        "print(baseline_df.round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ovtWVU11NTb",
        "outputId": "cea65c84-0c1d-4f81-9963-05465afc784c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Best Logistic Regression: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  # Required for l1 penalty\n",
        "}\n",
        "\n",
        "lr = LogisticRegression(random_state=42)\n",
        "grid_lr = GridSearchCV(lr, param_grid_lr, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "grid_lr.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_lr = grid_lr.best_estimator_\n",
        "print(\"âœ… Best Logistic Regression:\", grid_lr.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYoMGgdi1XlE",
        "outputId": "a7aa6c13-457b-4828-f971-d1bd6abe0b92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Best Decision Tree: {'min_samples_split': np.int64(5), 'min_samples_leaf': np.int64(9), 'max_depth': 5, 'criterion': 'gini'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_dist_dt = {\n",
        "    'max_depth': [3, 5, 7, 10, None],\n",
        "    'min_samples_split': np.arange(2, 20),\n",
        "    'min_samples_leaf': np.arange(1, 10),\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "random_dt = RandomizedSearchCV(dt, param_dist_dt, n_iter=100, cv=5, scoring='roc_auc', n_jobs=-1, random_state=42)\n",
        "random_dt.fit(X_train, y_train)\n",
        "\n",
        "best_dt = random_dt.best_estimator_\n",
        "print(\"âœ… Best Decision Tree:\", random_dt.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzKi_p2O1X-f",
        "outputId": "5a97a3dd-5609-4b6c-e527-17c5e9128c6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Best Random Forest: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 5, 'bootstrap': False}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Reduced search space\n",
        "param_dist_rf = {\n",
        "    'n_estimators': [100, 150, 200],           # Keep reasonable\n",
        "    'max_depth': [3, 5, 7, 10, None],          # Avoid very deep trees\n",
        "    'min_samples_split': [2, 5, 10],           # Common values\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2'],          # Important: reduces overfitting & speeds up\n",
        "    # Removed 'bootstrap': True is default; False rarely better\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Reduce n_iter and use faster CV\n",
        "random_rf = RandomizedSearchCV(\n",
        "    rf,\n",
        "    param_dist_rf,\n",
        "    n_iter=20,            # Reduced from 100 â†’ 20\n",
        "    cv=3,                 # Reduced from 5 â†’ 3 (still stable)\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=1             # Optional: see progress\n",
        ")\n",
        "\n",
        "# Fit\n",
        "random_rf.fit(X_train, y_train)\n",
        "\n",
        "best_rf = random_rf.best_estimator_\n",
        "print(\"âœ… Best Random Forest:\", random_rf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNsWLbvS1aOM",
        "outputId": "817dd951-91c5-4270-96cb-3843be5b54ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Best SVM: {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n"
          ]
        }
      ],
      "source": [
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
        "    'kernel': ['rbf', 'sigmoid']\n",
        "}\n",
        "\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "grid_svm = GridSearchCV(svm, param_grid_svm, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "best_svm = grid_svm.best_estimator_\n",
        "print(\"âœ… Best SVM:\", grid_svm.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etxvy8343aAL",
        "outputId": "65fec5b1-cc01-4dba-cd8c-4247dbbf8553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Optimized Model Performance:\n",
            "                 Model  Accuracy  Precision  Recall     F1    AUC\n",
            "0  Logistic Regression     0.885      0.862   0.893  0.877  0.951\n",
            "1        Decision Tree     0.754      0.810   0.607  0.694  0.735\n",
            "2        Random Forest     0.869      0.885   0.821  0.852  0.927\n",
            "3                  SVM     0.836      0.875   0.750  0.808  0.949\n"
          ]
        }
      ],
      "source": [
        "# List of best models\n",
        "optimized_models = {\n",
        "    \"Logistic Regression\": best_lr,\n",
        "    \"Decision Tree\": best_dt,\n",
        "    \"Random Forest\": best_rf,\n",
        "    \"SVM\": best_svm\n",
        "}\n",
        "\n",
        "# Evaluate optimized models\n",
        "optimized_results = []\n",
        "\n",
        "for name, model in optimized_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    optimized_results.append([name, acc, prec, rec, f1, auc])\n",
        "\n",
        "# Create DataFrame\n",
        "optimized_df = pd.DataFrame(optimized_results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"])\n",
        "print(\"\\nðŸ“Š Optimized Model Performance:\")\n",
        "print(optimized_df.round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm36BZgU2KR_",
        "outputId": "6682d167-bb5f-4e6d-a539-67a65d238513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Final Comparison: Baseline vs Optimized\n",
            "                         AUC           Accuracy                 F1            \\\n",
            "Status              Baseline Optimized Baseline Optimized Baseline Optimized   \n",
            "Model                                                                          \n",
            "Decision Tree          0.774     0.735    0.770     0.754    0.767     0.694   \n",
            "Logistic Regression    0.953     0.951    0.885     0.885    0.877     0.877   \n",
            "Random Forest          0.938     0.927    0.869     0.869    0.862     0.852   \n",
            "SVM                    0.955     0.949    0.902     0.836    0.889     0.808   \n",
            "\n",
            "                    Precision             Recall            \n",
            "Status               Baseline Optimized Baseline Optimized  \n",
            "Model                                                       \n",
            "Decision Tree           0.719     0.810    0.821     0.607  \n",
            "Logistic Regression     0.862     0.862    0.893     0.893  \n",
            "Random Forest           0.833     0.885    0.893     0.821  \n",
            "SVM                     0.923     0.875    0.857     0.750  \n"
          ]
        }
      ],
      "source": [
        "# Add identifier\n",
        "baseline_df['Status'] = 'Baseline'\n",
        "optimized_df['Status'] = 'Optimized'\n",
        "\n",
        "# Combine\n",
        "comparison = pd.concat([baseline_df, optimized_df], axis=0)\n",
        "comparison['Model_Status'] = comparison['Model'] + ' (' + comparison['Status'] + ')'\n",
        "\n",
        "# Select only metrics\n",
        "final_comp = comparison.pivot_table(\n",
        "    index='Model',\n",
        "    columns='Status',\n",
        "    values=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC']\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ“Š Final Comparison: Baseline vs Optimized\")\n",
        "print(final_comp.round(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTRzoS0A8NuA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
